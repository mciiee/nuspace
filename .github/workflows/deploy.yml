name: Build and Deploy

on:
  push:
    branches:
      - dev
      - main

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      GCLOUD_VERSION: '472.0.0'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Detect changed paths
        id: changes
        uses: dorny/paths-filter@v3
        with:
          token: ${{ github.token }}
          filters: |
            backend:
              - 'backend/**'
            frontend:
              - 'frontend/**'
            nginx:
              - 'infra/nginx/**'
            meilisearch:
              - 'infra/prod.docker-compose.yml'
            redis:
              - 'infra/redis/**'
            rabbitmq:
              - 'infra/rabbitmq/**'
            prometheus:
              - 'infra/prometheus/**'
            grafana:
              - 'infra/grafana/**'
            loki:
              - 'infra/loki/**'
            alloy:
              - 'infra/alloy/**'
            alertmanager:
              - 'infra/alertmanager/**'
            wireguard:
              - 'infra/wireguard/**'
            compose:
              - 'infra/prod.docker-compose.yml'

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          tags: |
            type=sha,format=short
            type=raw,value=latest

      # --- Build FastAPI Image ---
      - name: Build and Push FastAPI Image
        if: steps.changes.outputs.backend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./backend/Dockerfile
          push: true
          tags: kamikadze24/fastapi:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=fastapi
          cache-to: type=gha,mode=max,scope=fastapi

      # --- Build Celery Worker Image ---
      - name: Build and Push Celery Worker Image
        if: steps.changes.outputs.backend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./backend/Dockerfile_celery
          push: true
          tags: kamikadze24/celeryworker:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=celeryworker
          cache-to: type=gha,mode=max,scope=celeryworker

      # --- Build Frontend Builder Image ---
      - name: Build and Push Frontend Builder Image
        if: steps.changes.outputs.frontend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./frontend/Dockerfile_static_builder
          push: true
          tags: kamikadze24/frontendbuilder:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=frontend
          cache-to: type=gha,mode=max,scope=frontend

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Cache Google Cloud SDK
        uses: actions/cache@v4
        with:
          path: $HOME/google-cloud-sdk
          key: ${{ runner.os }}-gcloud-${{ env.GCLOUD_VERSION }}

      - name: Install Ansible and Google Cloud SDK
        run: |
          pip install --disable-pip-version-check ansible
          if [ ! -d "$HOME/google-cloud-sdk" ]; then
            curl -sSL https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-${GCLOUD_VERSION}-linux-x86_64.tar.gz -o /tmp/gcloud.tgz
            tar -xzf /tmp/gcloud.tgz -C $HOME
          fi
          echo "$HOME/google-cloud-sdk/bin" >> $GITHUB_PATH

      - name: Select GCP project and WIF provider based on branch
        run: |
          if [ "${GITHUB_REF_NAME}" = "main" ]; then
            echo "GCP_PROJECT=nuspace2025" >> $GITHUB_ENV
            echo "WIF_PROVIDER=projects/283390667737/locations/global/workloadIdentityPools/github-actions/providers/github-oidc" >> $GITHUB_ENV
            echo "WIF_SERVICE_ACCOUNT=nuspace-ansible-sa@nuspace2025.iam.gserviceaccount.com" >> $GITHUB_ENV
          else
            echo "GCP_PROJECT=nuspace-staging" >> $GITHUB_ENV
            echo "WIF_PROVIDER=projects/139212374894/locations/global/workloadIdentityPools/github-actions/providers/github-oidc" >> $GITHUB_ENV
            echo "WIF_SERVICE_ACCOUNT=nuspace-ansible-sa@nuspace-staging.iam.gserviceaccount.com" >> $GITHUB_ENV
          fi
          echo "ANSIBLE_GCP_PROJECT=${GCP_PROJECT}" >> $GITHUB_ENV

      - name: Authenticate to Google Cloud via Workload Identity Federation
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.WIF_PROVIDER }}
          service_account: ${{ env.WIF_SERVICE_ACCOUNT }}
          token_format: 'access_token'
          create_credentials_file: true
          access_token_scopes: 'https://www.googleapis.com/auth/cloud-platform'
          export_environment_variables: true

      - name: Set gcloud project
        run: |
          gcloud config set project "$GCP_PROJECT"

      - name: Get VM information and Docker credentials from Secret Manager
        id: secrets
        run: |
          # Debug: Show current gcloud auth info
          echo "Current gcloud account: $(gcloud auth list --filter=status:ACTIVE --format="value(account)")"
          echo "Current gcloud project: $(gcloud config get-value project)"
          
          # Explicitly set the account to use for gcloud commands
          gcloud config set account "$WIF_SERVICE_ACCOUNT"
          
          # Remove stale OS Login entries via API to prevent login profile overflow
          ACCESS_TOKEN=$(gcloud auth print-access-token)
          PRINCIPAL="serviceAccount:$WIF_SERVICE_ACCOUNT"
          ENCODED_PRINCIPAL=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1], safe=''))" "$PRINCIPAL")
          PROFILE_URL="https://oslogin.googleapis.com/v1/users/$ENCODED_PRINCIPAL?view=FULL"
          PROFILE_JSON=$(curl -s -H "Authorization: Bearer $ACCESS_TOKEN" "$PROFILE_URL" || echo '{}')

          TMP_KEYS=$(mktemp)
          printf '%s' "$PROFILE_JSON" | jq -r '.sshPublicKeys | keys[]?' 2>/dev/null > "$TMP_KEYS" || true
          if [ -s "$TMP_KEYS" ]; then
            while IFS= read -r KEY_NAME; do
              [ -z "$KEY_NAME" ] && continue
              ENCODED_KEY_NAME=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1], safe='/'))" "$KEY_NAME")
              if curl -s -X DELETE -H "Authorization: Bearer $ACCESS_TOKEN" "https://oslogin.googleapis.com/v1/$ENCODED_KEY_NAME" >/dev/null; then
                echo "Deleted OS Login SSH key: $KEY_NAME"
              else
                echo "Failed to delete SSH key: $KEY_NAME" >&2
              fi
            done < "$TMP_KEYS"
          else
            echo "No existing OS Login SSH keys found via OS Login API."
          fi
          rm -f "$TMP_KEYS"

          TMP_POSIX=$(mktemp)
          printf '%s' "$PROFILE_JSON" | jq -r '.posixAccounts[]?.name' 2>/dev/null > "$TMP_POSIX" || true
          if [ -s "$TMP_POSIX" ]; then
            while IFS= read -r POSIX_NAME; do
              [ -z "$POSIX_NAME" ] && continue
              ENCODED_POSIX_NAME=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1], safe='/'))" "$POSIX_NAME")
              if curl -s -X DELETE -H "Authorization: Bearer $ACCESS_TOKEN" "https://oslogin.googleapis.com/v1/$ENCODED_POSIX_NAME" >/dev/null; then
                echo "Deleted OS Login POSIX account: $POSIX_NAME"
              else
                echo "Failed to delete POSIX account: $POSIX_NAME" >&2
              fi
            done < "$TMP_POSIX"
          else
            echo "No POSIX accounts found to remove."
          fi
          rm -f "$TMP_POSIX"

          unset ACCESS_TOKEN

          # Get VM instance details using the service account
          VM_IP=$(gcloud compute instances describe nuspace-instance --zone=europe-central2-a --format="value(networkInterfaces[0].accessConfigs[0].natIP)")
          VM_NAME="nuspace-instance"
          # Derive OS Login POSIX username from service account unique ID (sa_<uniqueId>)
          SA_UNIQUE_ID=$(gcloud iam service-accounts describe "$WIF_SERVICE_ACCOUNT" --format="value(uniqueId)" || true)
          if [ -z "$SA_UNIQUE_ID" ]; then
            echo "Failed to get service account uniqueId for $WIF_SERVICE_ACCOUNT" >&2
            exit 1
          fi
          SA_USERNAME="sa_${SA_UNIQUE_ID}"
          echo "Using OS Login username: $SA_USERNAME"
          
          # Prime OS Login SSH certificate and verify access
          gcloud compute ssh "$VM_NAME" --zone=europe-central2-a --command="true" --ssh-flag="-o ConnectTimeout=10" --ssh-key-expire-after=1h --quiet || { echo "OS Login SSH failed. Ensure oslogin API is enabled and roles/compute.osAdminLogin is granted to $WIF_SERVICE_ACCOUNT" >&2; exit 1; }
          DOCKER_USERNAME=$(gcloud secrets versions access latest --secret="docker-username")
          DOCKER_PASSWORD=$(gcloud secrets versions access latest --secret="docker-password")
          echo "ANSIBLE_HOST=$VM_IP" >> $GITHUB_OUTPUT
          echo "VM_NAME=$VM_NAME" >> $GITHUB_OUTPUT
          echo "ANSIBLE_USER=$SA_USERNAME" >> $GITHUB_OUTPUT
          echo "DOCKER_USERNAME=$DOCKER_USERNAME" >> $GITHUB_OUTPUT
          echo "::add-mask::$DOCKER_PASSWORD"
          echo "DOCKER_PASSWORD=$DOCKER_PASSWORD" >> $GITHUB_OUTPUT

      - name: Check if containers are running on VM
        id: container_check
        run: |
          # Test connection and check container status using instance name
          gcloud compute ssh ${{ steps.secrets.outputs.VM_NAME }} --zone=europe-central2-a --command="docker ps --format 'table {{.Names}}\t{{.Status}}'" --ssh-flag="-o ConnectTimeout=10" --quiet > /tmp/container_status.txt 2>/dev/null || echo "Connection failed" > /tmp/container_status.txt
          
          # Check if expected containers are running
          if grep -q "fastapi\|celery-worker\|nginx\|redis\|rabbitmq\|prometheus\|grafana\|loki\|alloy\|alertmanager\|wireguard" /tmp/container_status.txt; then
            echo "containers_running=true" >> $GITHUB_OUTPUT
          else
            echo "containers_running=false" >> $GITHUB_OUTPUT
          fi
          
          # Always run if there are code changes
          if [[ "${{ steps.changes.outputs.backend }}" == "true" || "${{ steps.changes.outputs.frontend }}" == "true" || "${{ steps.changes.outputs.nginx }}" == "true" || "${{ steps.changes.outputs.redis }}" == "true" || "${{ steps.changes.outputs.rabbitmq }}" == "true" || "${{ steps.changes.outputs.prometheus }}" == "true" || "${{ steps.changes.outputs.grafana }}" == "true" || "${{ steps.changes.outputs.loki }}" == "true" || "${{ steps.changes.outputs.alloy }}" == "true" || "${{ steps.changes.outputs.alertmanager }}" == "true" || "${{ steps.changes.outputs.wireguard }}" == "true" || "${{ steps.changes.outputs.compose }}" == "true" ]]; then
            echo "should_deploy=true" >> $GITHUB_OUTPUT
          else
            echo "should_deploy=false" >> $GITHUB_OUTPUT
          fi

      - name: Create Ansible configuration
        run: |
          cat > ansible/ansible.cfg << EOF
          [defaults]
          remote_tmp = /tmp
          local_tmp = /tmp
          host_key_checking = False
          timeout = 60
          gathering = explicit
          fact_caching = memory
          ansible_managed = Ansible managed
          
          [ssh_connection]
          ssh_args = 
          control_path_dir = /tmp
          EOF

      - name: Create inventory file
        run: |
          cat > ansible/inventory.yml << EOF
          ---
          all:
            children:
              webservers:
                hosts:
                  ${{ steps.secrets.outputs.VM_NAME }}:
                    ansible_host: ${{ steps.secrets.outputs.ANSIBLE_HOST }}
                    ansible_user: ${{ steps.secrets.outputs.ANSIBLE_USER }}
                    ansible_ssh_private_key_file: ~/.ssh/google_compute_engine
                    ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o CertificateFile=~/.ssh/google_compute_engine-cert.pub'
                    ansible_become: yes
                    ansible_become_method: sudo
                    ansible_remote_tmp: /tmp
                    ansible_shell_type: sh
          EOF

      - name: Run Ansible Playbook
        env:
          ANSIBLE_HOST_KEY_CHECKING: False
          ANSIBLE_REMOTE_TMP: /tmp
          ANSIBLE_LOCAL_TMP: /tmp
        run: |
          # Test OS Login connection and prepare environment
          gcloud compute ssh ${{ steps.secrets.outputs.VM_NAME }} --zone=europe-central2-a --command="echo 'OS Login configured'" --ssh-flag="-o ConnectTimeout=10" --quiet || true
          
          # Run the Ansible playbook
          cd ansible && ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook playbook.yml \
            --inventory inventory.yml \
            --extra-vars "docker_image_tag=${{ steps.meta.outputs.version }} ansible_user_var=${{ steps.secrets.outputs.ANSIBLE_USER }} docker_user=${{ steps.secrets.outputs.DOCKER_USERNAME }} docker_pass=${{ steps.secrets.outputs.DOCKER_PASSWORD }} gcp_project=${{ env.GCP_PROJECT }} github_ref_name=${{ github.ref_name }} backend_changed=${{ steps.changes.outputs.backend }} frontend_changed=${{ steps.changes.outputs.frontend }} nginx_changed=${{ steps.changes.outputs.nginx }} redis_changed=${{ steps.changes.outputs.redis }} rabbitmq_changed=${{ steps.changes.outputs.rabbitmq }} prometheus_changed=${{ steps.changes.outputs.prometheus }} grafana_changed=${{ steps.changes.outputs.grafana }} loki_changed=${{ steps.changes.outputs.loki }} alloy_changed=${{ steps.changes.outputs.alloy }} alertmanager_changed=${{ steps.changes.outputs.alertmanager }} wireguard_changed=${{ steps.changes.outputs.wireguard }} meilisearch_changed=${{ steps.changes.outputs.meilisearch }} compose_changed=${{ steps.changes.outputs.compose }} force_frontend_build=true"

      - name: Cleanup OS Login SSH key
        if: always()
        run: |
          gcloud config set project "$GCP_PROJECT"
          gcloud config set account "$WIF_SERVICE_ACCOUNT"
          if [ -f "$HOME/.ssh/google_compute_engine.pub" ]; then
            echo "Removing OS Login SSH key for $WIF_SERVICE_ACCOUNT"
            ACCESS_TOKEN=$(gcloud auth print-access-token)
            PRINCIPAL="serviceAccount:$WIF_SERVICE_ACCOUNT"
            ENCODED_PRINCIPAL=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1], safe=''))" "$PRINCIPAL")
            PROFILE_URL="https://oslogin.googleapis.com/v1/users/$ENCODED_PRINCIPAL?view=FULL"
            PROFILE_JSON=$(curl -s -H "Authorization: Bearer $ACCESS_TOKEN" "$PROFILE_URL" || echo '{}')
            PUB_KEY=$(cat "$HOME/.ssh/google_compute_engine.pub")
            MATCHING_FPS=$(echo "$PROFILE_JSON" | jq -r --arg KEY "$PUB_KEY" '.sshPublicKeys | to_entries[]? | select(.value.key==$KEY) | .key' 2>/dev/null || true)
            TMP_MATCH=$(mktemp)
            printf '%s' "$MATCHING_FPS" > "$TMP_MATCH"
            if [ -s "$TMP_MATCH" ]; then
              while IFS= read -r FINGERPRINT; do
                [ -z "$FINGERPRINT" ] && continue
                ENCODED_FP=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1], safe='/'))" "$FINGERPRINT")
                if curl -s -X DELETE -H "Authorization: Bearer $ACCESS_TOKEN" "https://oslogin.googleapis.com/v1/$ENCODED_FP" >/dev/null; then
                  echo "Deleted OS Login SSH key fingerprint: $FINGERPRINT"
                else
                  echo "Failed to delete OS Login key fingerprint: $FINGERPRINT" >&2
                fi
              done < "$TMP_MATCH"
            else
              echo "No matching OS Login SSH key found to remove."
            fi
            rm -f "$TMP_MATCH"
            unset ACCESS_TOKEN
          else
            echo "No local SSH public key found for cleanup."
          fi
          rm -f "$HOME/.ssh/google_compute_engine" "$HOME/.ssh/google_compute_engine-cert.pub" "$HOME/.ssh/google_compute_engine.pub"
