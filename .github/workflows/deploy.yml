name: Build and Deploy

on:
  push:
    branches:
      - dev
      - main

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      GCLOUD_VERSION: '472.0.0'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Detect changed paths
        id: changes
        uses: dorny/paths-filter@v3
        with:
          token: ${{ github.token }}
          filters: |
            backend:
              - 'backend/**'
            frontend:
              - 'frontend/**'
            nginx:
              - 'infra/nginx/**'
            meilisearch:
              - 'infra/prod.docker-compose.yml'
            redis:
              - 'infra/redis/**'
            rabbitmq:
              - 'infra/rabbitmq/**'
            prometheus:
              - 'infra/prometheus/**'
            grafana:
              - 'infra/grafana/**'
            loki:
              - 'infra/loki/**'
            alloy:
              - 'infra/alloy/**'
            alertmanager:
              - 'infra/alertmanager/**'
            wireguard:
              - 'infra/wireguard/**'
            compose:
              - 'infra/prod.docker-compose.yml'

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          tags: |
            type=sha,format=short
            type=raw,value=latest

      # --- Build FastAPI Image ---
      - name: Build and Push FastAPI Image
        if: steps.changes.outputs.backend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./backend/Dockerfile
          push: true
          tags: kamikadze24/fastapi:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=fastapi
          cache-to: type=gha,mode=max,scope=fastapi

      # --- Build Celery Worker Image ---
      - name: Build and Push Celery Worker Image
        if: steps.changes.outputs.backend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./backend/Dockerfile_celery
          push: true
          tags: kamikadze24/celeryworker:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=celeryworker
          cache-to: type=gha,mode=max,scope=celeryworker

      # --- Build Frontend Builder Image ---
      - name: Build and Push Frontend Builder Image
        if: steps.changes.outputs.frontend == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./frontend/Dockerfile_static_builder
          push: true
          tags: kamikadze24/frontendbuilder:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha,scope=frontend
          cache-to: type=gha,mode=max,scope=frontend

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      - name: Cache Google Cloud SDK
        uses: actions/cache@v4
        with:
          path: $HOME/google-cloud-sdk
          key: ${{ runner.os }}-gcloud-${{ env.GCLOUD_VERSION }}

      - name: Install Ansible and Google Cloud SDK
        run: |
          pip install --disable-pip-version-check ansible
          if [ ! -d "$HOME/google-cloud-sdk" ]; then
            curl -sSL https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-${GCLOUD_VERSION}-linux-x86_64.tar.gz -o /tmp/gcloud.tgz
            tar -xzf /tmp/gcloud.tgz -C $HOME
          fi
          echo "$HOME/google-cloud-sdk/bin" >> $GITHUB_PATH

      - name: Select GCP project and WIF provider based on branch
        run: |
          if [ "${GITHUB_REF_NAME}" = "main" ]; then
            echo "GCP_PROJECT=nuspace2025" >> $GITHUB_ENV
            echo "WIF_PROVIDER=projects/283390667737/locations/global/workloadIdentityPools/github-actions/providers/github-oidc" >> $GITHUB_ENV
            echo "WIF_SERVICE_ACCOUNT=nuspace-ansible-sa@nuspace2025.iam.gserviceaccount.com" >> $GITHUB_ENV
          else
            echo "GCP_PROJECT=nuspace-staging" >> $GITHUB_ENV
            echo "WIF_PROVIDER=projects/139212374894/locations/global/workloadIdentityPools/github-actions/providers/github-oidc" >> $GITHUB_ENV
            echo "WIF_SERVICE_ACCOUNT=nuspace-ansible-sa@nuspace-staging.iam.gserviceaccount.com" >> $GITHUB_ENV
          fi
          echo "ANSIBLE_GCP_PROJECT=${GCP_PROJECT}" >> $GITHUB_ENV

      - name: Authenticate to Google Cloud via Workload Identity Federation
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.WIF_PROVIDER }}
          service_account: ${{ env.WIF_SERVICE_ACCOUNT }}
          token_format: 'access_token'
          create_credentials_file: true
          access_token_scopes: 'https://www.googleapis.com/auth/cloud-platform'
          export_environment_variables: true

      - name: Set gcloud project
        run: |
          gcloud config set project "$GCP_PROJECT"

      - name: Get VM information and Docker credentials from Secret Manager
        id: secrets
        run: |
          # Debug: Show current gcloud auth info
          echo "Current gcloud account: $(gcloud auth list --filter=status:ACTIVE --format="value(account)")"
          echo "Current gcloud project: $(gcloud config get-value project)"
          
          # Explicitly set the account to use for gcloud commands
          gcloud config set account "$WIF_SERVICE_ACCOUNT"
          
          # Remove stale OS Login entries via API to prevent login profile overflow
          ACCESS_TOKEN=$(gcloud auth print-access-token)
          export ACCESS_TOKEN WIF_SERVICE_ACCOUNT
          python - <<'PY'
import json
import os
import sys
import urllib.error
import urllib.parse
import urllib.request

principal = f"serviceAccount:{os.environ['WIF_SERVICE_ACCOUNT']}"
encoded_user = urllib.parse.quote(principal, safe='')
token = os.environ['ACCESS_TOKEN']
headers = {
    "Authorization": f"Bearer {token}",
    "Accept": "application/json"
}

def api_request(url: str, method: str = "GET"):
    req = urllib.request.Request(url, headers=headers, method=method)
    with urllib.request.urlopen(req) as resp:
        body = resp.read()
        if not body:
            return None
        return json.loads(body)

profile_url = f"https://oslogin.googleapis.com/v1/users/{encoded_user}?view=FULL"
try:
    profile = api_request(profile_url) or {}
except urllib.error.HTTPError as exc:
    print(f"Failed to fetch OS Login profile: {exc}", file=sys.stderr)
    profile = {}
except urllib.error.URLError as exc:
    print(f"Failed to reach OS Login API: {exc}", file=sys.stderr)
    profile = {}

ssh_keys = profile.get("sshPublicKeys", {})
if ssh_keys:
    for name in list(ssh_keys.keys()):
        delete_url = "https://oslogin.googleapis.com/v1/" + urllib.parse.quote(name, safe='/')
        try:
            api_request(delete_url, method="DELETE")
            print(f"Deleted OS Login SSH key: {name}")
        except urllib.error.HTTPError as exc:
            print(f"Failed to delete SSH key {name}: {exc}", file=sys.stderr)
        except urllib.error.URLError as exc:
            print(f"Network error removing SSH key {name}: {exc}", file=sys.stderr)
else:
    print("No existing OS Login SSH keys found via OS Login API.")

posix_accounts = profile.get("posixAccounts", [])
kept_projects = set()
removed_posix = 0
for entry in posix_accounts:
    name = entry.get("name")
    project_id = entry.get("projectId")
    if not name:
        continue
    if project_id and project_id not in kept_projects:
        kept_projects.add(project_id)
        continue
    delete_url = "https://oslogin.googleapis.com/v1/" + urllib.parse.quote(name, safe='/')
    try:
        api_request(delete_url, method="DELETE")
        removed_posix += 1
        print(f"Deleted stale OS Login POSIX account: {name}")
    except urllib.error.HTTPError as exc:
        print(f"Failed to delete POSIX account {name}: {exc}", file=sys.stderr)
    except urllib.error.URLError as exc:
        print(f"Network error removing POSIX account {name}: {exc}", file=sys.stderr)

if removed_posix == 0:
    print("No stale POSIX accounts removed.")
else:
    print(f"Removed {removed_posix} stale POSIX account entries.")
PY
          unset ACCESS_TOKEN WIF_SERVICE_ACCOUNT

          # Get VM instance details using the service account
          VM_IP=$(gcloud compute instances describe nuspace-instance --zone=europe-central2-a --format="value(networkInterfaces[0].accessConfigs[0].natIP)")
          VM_NAME="nuspace-instance"
          # Derive OS Login POSIX username from service account unique ID (sa_<uniqueId>)
          SA_UNIQUE_ID=$(gcloud iam service-accounts describe "$WIF_SERVICE_ACCOUNT" --format="value(uniqueId)" || true)
          if [ -z "$SA_UNIQUE_ID" ]; then
            echo "Failed to get service account uniqueId for $WIF_SERVICE_ACCOUNT" >&2
            exit 1
          fi
          SA_USERNAME="sa_${SA_UNIQUE_ID}"
          echo "Using OS Login username: $SA_USERNAME"
          
          # Prime OS Login SSH certificate and verify access
          gcloud compute ssh "$VM_NAME" --zone=europe-central2-a --command="true" --ssh-flag="-o ConnectTimeout=10" --ssh-key-expire-after=1h --quiet || { echo "OS Login SSH failed. Ensure oslogin API is enabled and roles/compute.osAdminLogin is granted to $WIF_SERVICE_ACCOUNT" >&2; exit 1; }
          DOCKER_USERNAME=$(gcloud secrets versions access latest --secret="docker-username")
          DOCKER_PASSWORD=$(gcloud secrets versions access latest --secret="docker-password")
          echo "ANSIBLE_HOST=$VM_IP" >> $GITHUB_OUTPUT
          echo "VM_NAME=$VM_NAME" >> $GITHUB_OUTPUT
          echo "ANSIBLE_USER=$SA_USERNAME" >> $GITHUB_OUTPUT
          echo "DOCKER_USERNAME=$DOCKER_USERNAME" >> $GITHUB_OUTPUT
          echo "::add-mask::$DOCKER_PASSWORD"
          echo "DOCKER_PASSWORD=$DOCKER_PASSWORD" >> $GITHUB_OUTPUT

      - name: Check if containers are running on VM
        id: container_check
        run: |
          # Test connection and check container status using instance name
          gcloud compute ssh ${{ steps.secrets.outputs.VM_NAME }} --zone=europe-central2-a --command="docker ps --format 'table {{.Names}}\t{{.Status}}'" --ssh-flag="-o ConnectTimeout=10" --quiet > /tmp/container_status.txt 2>/dev/null || echo "Connection failed" > /tmp/container_status.txt
          
          # Check if expected containers are running
          if grep -q "fastapi\|celery-worker\|nginx\|redis\|rabbitmq\|prometheus\|grafana\|loki\|alloy\|alertmanager\|wireguard" /tmp/container_status.txt; then
            echo "containers_running=true" >> $GITHUB_OUTPUT
          else
            echo "containers_running=false" >> $GITHUB_OUTPUT
          fi
          
          # Always run if there are code changes
          if [[ "${{ steps.changes.outputs.backend }}" == "true" || "${{ steps.changes.outputs.frontend }}" == "true" || "${{ steps.changes.outputs.nginx }}" == "true" || "${{ steps.changes.outputs.redis }}" == "true" || "${{ steps.changes.outputs.rabbitmq }}" == "true" || "${{ steps.changes.outputs.prometheus }}" == "true" || "${{ steps.changes.outputs.grafana }}" == "true" || "${{ steps.changes.outputs.loki }}" == "true" || "${{ steps.changes.outputs.alloy }}" == "true" || "${{ steps.changes.outputs.alertmanager }}" == "true" || "${{ steps.changes.outputs.wireguard }}" == "true" || "${{ steps.changes.outputs.compose }}" == "true" ]]; then
            echo "should_deploy=true" >> $GITHUB_OUTPUT
          else
            echo "should_deploy=false" >> $GITHUB_OUTPUT
          fi

      - name: Create Ansible configuration
        run: |
          cat > ansible/ansible.cfg << EOF
          [defaults]
          remote_tmp = /tmp
          local_tmp = /tmp
          host_key_checking = False
          timeout = 60
          gathering = explicit
          fact_caching = memory
          ansible_managed = Ansible managed
          
          [ssh_connection]
          ssh_args = 
          control_path_dir = /tmp
          EOF

      - name: Create inventory file
        run: |
          cat > ansible/inventory.yml << EOF
          ---
          all:
            children:
              webservers:
                hosts:
                  ${{ steps.secrets.outputs.VM_NAME }}:
                    ansible_host: ${{ steps.secrets.outputs.ANSIBLE_HOST }}
                    ansible_user: ${{ steps.secrets.outputs.ANSIBLE_USER }}
                    ansible_ssh_private_key_file: ~/.ssh/google_compute_engine
                    ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o CertificateFile=~/.ssh/google_compute_engine-cert.pub'
                    ansible_become: yes
                    ansible_become_method: sudo
                    ansible_remote_tmp: /tmp
                    ansible_shell_type: sh
          EOF

      - name: Run Ansible Playbook
        env:
          ANSIBLE_HOST_KEY_CHECKING: False
          ANSIBLE_REMOTE_TMP: /tmp
          ANSIBLE_LOCAL_TMP: /tmp
        run: |
          # Test OS Login connection and prepare environment
          gcloud compute ssh ${{ steps.secrets.outputs.VM_NAME }} --zone=europe-central2-a --command="echo 'OS Login configured'" --ssh-flag="-o ConnectTimeout=10" --quiet || true
          
          # Run the Ansible playbook
          cd ansible && ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook playbook.yml \
            --inventory inventory.yml \
            --extra-vars "docker_image_tag=${{ steps.meta.outputs.version }} ansible_user_var=${{ steps.secrets.outputs.ANSIBLE_USER }} docker_user=${{ steps.secrets.outputs.DOCKER_USERNAME }} docker_pass=${{ steps.secrets.outputs.DOCKER_PASSWORD }} gcp_project=${{ env.GCP_PROJECT }} github_ref_name=${{ github.ref_name }} backend_changed=${{ steps.changes.outputs.backend }} frontend_changed=${{ steps.changes.outputs.frontend }} nginx_changed=${{ steps.changes.outputs.nginx }} redis_changed=${{ steps.changes.outputs.redis }} rabbitmq_changed=${{ steps.changes.outputs.rabbitmq }} prometheus_changed=${{ steps.changes.outputs.prometheus }} grafana_changed=${{ steps.changes.outputs.grafana }} loki_changed=${{ steps.changes.outputs.loki }} alloy_changed=${{ steps.changes.outputs.alloy }} alertmanager_changed=${{ steps.changes.outputs.alertmanager }} wireguard_changed=${{ steps.changes.outputs.wireguard }} meilisearch_changed=${{ steps.changes.outputs.meilisearch }} compose_changed=${{ steps.changes.outputs.compose }} force_frontend_build=true"

      - name: Cleanup OS Login SSH key
        if: always()
        run: |
          gcloud config set project "$GCP_PROJECT"
          gcloud config set account "$WIF_SERVICE_ACCOUNT"
          if [ -f "$HOME/.ssh/google_compute_engine.pub" ]; then
            echo "Removing OS Login SSH key for $WIF_SERVICE_ACCOUNT"
            ACCESS_TOKEN=$(gcloud auth print-access-token)
            export ACCESS_TOKEN WIF_SERVICE_ACCOUNT PUB_KEY_PATH="$HOME/.ssh/google_compute_engine.pub"
            python - <<'PY'
import os
import sys
import urllib.error
import urllib.parse
import urllib.request

principal = f"serviceAccount:{os.environ['WIF_SERVICE_ACCOUNT']}"
token = os.environ['ACCESS_TOKEN']
pub_key_path = os.environ['PUB_KEY_PATH']

with open(pub_key_path, 'r', encoding='utf-8') as fh:
    key_contents = fh.read().strip()

encoded_key = urllib.parse.quote(key_contents, safe='')
url = (
    "https://oslogin.googleapis.com/v1/users/"
    + urllib.parse.quote(principal, safe='')
    + f"/sshPublicKeys/{encoded_key}"
)

headers = {
    "Authorization": f"Bearer {token}",
    "Accept": "application/json",
}

req = urllib.request.Request(url, headers=headers, method="DELETE")
try:
    urllib.request.urlopen(req)
    print("Deleted OS Login SSH key uploaded in this run.")
except urllib.error.HTTPError as exc:
    if exc.code == 404:
        print("No matching OS Login SSH key found to remove.")
    else:
        print(f"Failed to delete OS Login key: {exc}", file=sys.stderr)
except urllib.error.URLError as exc:
    print(f"Network error removing OS Login key: {exc}", file=sys.stderr)
PY
            unset ACCESS_TOKEN WIF_SERVICE_ACCOUNT PUB_KEY_PATH
          else
            echo "No local SSH public key found for cleanup."
          fi
          rm -f "$HOME/.ssh/google_compute_engine" "$HOME/.ssh/google_compute_engine-cert.pub"
          rm -f "$HOME/.ssh/google_compute_engine.pub"
